# AI Stack Template

A complete, self-hosted AI development stack with Ollama, n8n, React frontend, and Node.js backend.

## ğŸ¯ What This Template Provides

- **ğŸ¤– Self-hosted AI**: Local LLM serving with Ollama (Phi-3, Llama2, etc.)
- **ğŸ”„ Workflow Automation**: n8n for AI workflow orchestration
- **ğŸ’¬ Chat Interface**: React-based frontend with real-time AI chat
- **ğŸ”Œ REST API**: Node.js backend with PostgreSQL integration
- **ğŸ“Š Example Integration**: Stock price lookup demo
- **ğŸ³ Containerized**: Complete Docker setup with one-command deployment

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose installed
- At least 8GB RAM (for AI models)
- 10GB free disk space

### One-Command Setup
```bash
chmod +x quick-start.sh
./quick-start.sh
```

### Manual Setup
```bash
# 1. Generate project structure
chmod +x install.sh
./install.sh

# 2. Start all services
docker-compose up -d

# 3. Setup AI models (interactive)
./scripts/setup-ollama.sh
```

## ğŸ”— Access Points

Once running, access these services:

- **ğŸ’¬ Chat Interface**: http://localhost:3000
- **âš™ï¸ n8n Workflows**: http://localhost:5678
- **ğŸ”Œ Backend API**: http://localhost:3001
- **ğŸ¤– Ollama API**: http://localhost:11434

## ğŸ› ï¸ Management

Use the management script for easy operations:

```bash
./manage.sh status    # Check all services
./manage.sh logs      # View logs
./manage.sh models    # Manage AI models
./manage.sh backup    # Create backups
./manage.sh clean     # Clean up containers
```

## ğŸ“‹ What Gets Created

The install script generates:
```
ai-stack-template/
â”œâ”€â”€ backend/          # Node.js API server
â”œâ”€â”€ frontend/         # React chat application  
â”œâ”€â”€ n8n/             # Workflow configurations
â”œâ”€â”€ scripts/         # Utility scripts
â””â”€â”€ docker-compose.yml # Service orchestration
```

## ğŸ”§ Customization

### Adding New AI Models
```bash
./manage.sh models pull mistral:7b
# Then update frontend model selector
```

### Creating Custom Workflows
1. Visit http://localhost:5678
2. Create new workflow
3. Use webhook: `http://n8n:5678/webhook/your-path`

### Extending the API
Edit `backend/server.js` to add new endpoints and integrate with your workflows.

## ğŸ¨ Example Features

- **Multi-model Chat**: Switch between different AI models
- **Conversation History**: Persistent chat storage
- **Stock Price Demo**: External API integration example
- **Real-time Responses**: WebSocket-like experience via n8n

## ğŸ”’ Security Notes

âš ï¸ **This is a development template**

For production deployment:
- Enable authentication in n8n
- Use environment secrets management
- Implement rate limiting
- Add SSL/HTTPS
- Secure database access

## ğŸ“š Documentation

- [Setup Guide](setup-n8n-credentials.md) - n8n credentials and configuration
- [Project Structure](project-structure.md) - Detailed architecture overview
- [API Documentation](http://localhost:3001/health) - Backend API reference

## ğŸ› Troubleshooting

### Services Won't Start
```bash
docker-compose logs    # Check for errors
docker system df       # Check disk space
```

### Models Not Loading
```bash
./manage.sh models list     # Check installed models
docker logs ollama          # Check Ollama logs
```

### Reset Everything
```bash
./manage.sh reset    # Nuclear option - deletes all data
```

## ğŸ¤ Contributing

This template is designed to be customized for your specific needs. Fork it, modify it, and build amazing AI applications!

## ğŸ“ License

Open source template for development and learning purposes.# AI Stack Template

A complete, self-hosted AI development stack with Ollama, n8n, React frontend, and Node.js backend.

## ğŸ¯ What This Template Provides

- **ğŸ¤– Self-hosted AI**: Local LLM serving with Ollama (Phi-3, Llama2, etc.)
- **ğŸ”„ Workflow Automation**: n8n for AI workflow orchestration
- **ğŸ’¬ Chat Interface**: React-based frontend with real-time AI chat
- **ğŸ”Œ REST API**: Node.js backend with PostgreSQL integration
- **ğŸ“Š Example Integration**: Stock price lookup demo
- **ğŸ³ Containerized**: Complete Docker setup with one-command deployment

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose installed
- At least 8GB RAM (for AI models)
- 10GB free disk space

### One-Command Setup
```bash
chmod +x quick-start.sh
./quick-start.sh
```

### Manual Setup
```bash
# 1. Generate project structure
chmod +x install.sh
./install.sh

# 2. Start all services
docker-compose up -d

# 3. Setup AI models (interactive)
./scripts/setup-ollama.sh
```

## ğŸ“‹ Importing the n8n Workflow

After starting the services:

1. Open n8n at http://localhost:5678
2. Click **"Workflows"** â†’ **"Import from File"**  
3. Select `n8n-workflow-chat.json` from the project root
4. **Important**: Activate the workflow (toggle in top-right)
5. Test the chat at http://localhost:3000

The workflow connects: **Webhook â†’ Ollama â†’ Respond to Webhook**

## ğŸ”— Access Points

Once running, access these services:

- **ğŸ’¬ Chat Interface**: http://localhost:3000
- **âš™ï¸ n8n Workflows**: http://localhost:5678
- **ğŸ”Œ Backend API**: http://localhost:3001
- **ğŸ¤– Ollama API**: http://localhost:11434

## ğŸ› ï¸ Management

Use the management script for easy operations:

```bash
./manage.sh status    # Check all services
./manage.sh logs      # View logs
./manage.sh models    # Manage AI models
./manage.sh backup    # Create backups
./manage.sh clean     # Clean up containers
```

## ğŸ“‹ What Gets Created

The install script generates:
```
ai-stack-template/
â”œâ”€â”€ backend/          # Node.js API server
â”œâ”€â”€ frontend/         # React chat application  
â”œâ”€â”€ n8n/             # Workflow configurations
â”œâ”€â”€ scripts/         # Utility scripts
â””â”€â”€ docker-compose.yml # Service orchestration
```

## ğŸ”§ Customization

### Adding New AI Models
```bash
./manage.sh models pull mistral:7b
# Then update frontend model selector
```

### Creating Custom Workflows
1. Visit http://localhost:5678
2. Create new workflow
3. Use webhook: `http://n8n:5678/webhook/your-path`

### Extending the API
Edit `backend/server.js` to add new endpoints and integrate with your workflows.

## ğŸ¨ Example Features

- **Multi-model Chat**: Switch between different AI models
- **Conversation History**: Persistent chat storage
- **Stock Price Demo**: External API integration example
- **Real-time Responses**: WebSocket-like experience via n8n

## ğŸ”’ Security Notes

âš ï¸ **This is a development template**

For production deployment:
- Enable authentication in n8n
- Use environment secrets management
- Implement rate limiting
- Add SSL/HTTPS
- Secure database access

## ğŸ“š Documentation

- [Setup Guide](setup-n8n-credentials.md) - n8n credentials and configuration
- [Project Structure](project-structure.md) - Detailed architecture overview
- [API Documentation](http://localhost:3001/health) - Backend API reference

## ğŸ› Troubleshooting

### Services Won't Start
```bash
docker-compose logs    # Check for errors
docker system df       # Check disk space
```

### Models Not Loading
```bash
./manage.sh models list     # Check installed models
docker logs ollama          # Check Ollama logs
```

### Reset Everything
```bash
./manage.sh reset    # Nuclear option - deletes all data
```

## ğŸ¤ Contributing

This template is designed to be customized for your specific needs. Fork it, modify it, and build amazing AI applications!

## ğŸ“ License

Open source template for development and learning purposes.